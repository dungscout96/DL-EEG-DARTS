{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "2c0_0uImBwm5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y, train):\n",
    "        super(EEGDataset).__init__()\n",
    "        assert x.shape[0] == y.size\n",
    "        self.x = x\n",
    "        #temp_y = np.zeros((y.size, 2))\n",
    "        #for i in range(y.size):\n",
    "        #    temp_y[i, y[i]] = 1\n",
    "        #self.y = temp_y\n",
    "        self.y = [y[i][0] for i in range(y.size)]\n",
    "        self.train = train\n",
    "        \n",
    "    def __getitem__(self,key):\n",
    "        return (self.x[key], self.y[key])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (71300, 1, 24, 256)\n",
      "Y_train shape: (71300, 1)\n",
      "X_val shape: (39868, 1, 24, 256)\n",
      "Y_val shape: (39868, 1)\n",
      "X_test shape: (16006, 1, 24, 256)\n",
      "Y_test shape: (16006, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load EEG data\n",
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "            ])\n",
    "f = h5py.File('child_mind_x_train_v2.mat', 'r')\n",
    "x_train = f['X_train']\n",
    "x_train = np.reshape(x_train,(-1,1,24,256))\n",
    "print('X_train shape: ' + str(x_train.shape))\n",
    "f = h5py.File('child_mind_y_train_v2.mat', 'r')\n",
    "y_train = f['Y_train']\n",
    "print('Y_train shape: ' + str(y_train.shape))\n",
    "train_data = EEGDataset(x_train, y_train, True)\n",
    "loader_train = DataLoader(train_data, batch_size=70)\n",
    "\n",
    "f = h5py.File('child_mind_x_val_v2.mat', 'r')\n",
    "x_val = f['X_val']\n",
    "x_val = np.reshape(x_val,(-1,1,24,256))\n",
    "print('X_val shape: ' + str(x_val.shape))\n",
    "f = h5py.File('child_mind_y_val_v2.mat', 'r')\n",
    "y_val = f['Y_val']\n",
    "print('Y_val shape: ' + str(y_val.shape))\n",
    "val_data = EEGDataset(x_val, y_val, True)\n",
    "loader_val = DataLoader(val_data, batch_size=70)\n",
    "\n",
    "f = h5py.File('child_mind_x_test_v2.mat', 'r')\n",
    "x_test = f['X_test']\n",
    "x_test = np.reshape(x_test,(-1,1,24,256))\n",
    "print('X_test shape: ' + str(x_test.shape))\n",
    "f = h5py.File('child_mind_y_test_v2.mat', 'r')\n",
    "y_test = f['Y_test']\n",
    "print('Y_test shape: ' + str(y_test.shape))\n",
    "test_data = EEGDataset(x_test, y_test, False)\n",
    "loader_test = DataLoader(test_data, batch_size=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.histogram(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with MNIST\n",
    "import torchvision.datasets as dset\n",
    "NUM_TRAIN = 700\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.CenterCrop(24),\n",
    "                T.Pad((116,0))\n",
    "            ])\n",
    "mnist_train = dset.MNIST('./mnist', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(mnist_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "mnist_val = dset.MNIST('./mnist', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(mnist_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "mnist_test = dset.MNIST('./mnist', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(mnist_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZSqENpKfB2UE"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                      nn.Conv2d(1,100,3),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(2, 2),\n",
    "                      nn.Dropout(0.25),\n",
    "                      nn.Conv2d(100,100,3),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(2, 2),\n",
    "                      nn.Dropout(0.25),\n",
    "                      nn.Conv2d(100,300,(2,3)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(2, 2),\n",
    "                      nn.Dropout(0.25),\n",
    "                      nn.Conv2d(300,300,(1,7)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d((1,2), stride=1),\n",
    "                      nn.Dropout(0.25),\n",
    "                      nn.Conv2d(300,100,(1,3)),\n",
    "                      nn.Conv2d(100,100,(1,3)),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(1900,6144),\n",
    "                      nn.Linear(6144,2),\n",
    ")\n",
    "\n",
    "pred = model(next(iter(loader_train))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6_vK1KY8UKzb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.3249\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 100, loss = 0.0076\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 200, loss = 2.1681\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 300, loss = 0.7080\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 400, loss = 0.1833\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 500, loss = 0.0403\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 600, loss = 3.7696\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n",
      "Iteration 700, loss = 0.0373\n",
      "Checking accuracy on validation set\n",
      "Got 23507 / 29274 correct (80.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters(), lr=2e-3)\n",
    "train(model, optimizer, epohcs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 9040 / 11146 correct (81.11)\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "check_accuracy(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SexPrediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
